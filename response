To Reviewer #1:
Q1: The definition of the two anomalies is not clear in Introduction. The description of structure anomalies is inconsistent in Introduction and Structure Masking.
R1: This paper mainly focus on two anomalous types: attribute and structure.The attribute anomaly is caused by the attribute difference between abnormal and normal nodes in the feature space, i.e., the attributes of abnormal nodes are significantly different from their neighboring nodes. Structural anomalies usually camouflage themselves by mimicking normal nodes’ attributes for escape and we cannot discover them through measuring the attribute difference
Q2: The author should prove the effectiveness of the model for structure anomaly detection from theoretical or experimental analysis.
R2: Good proposal ! In fact, many literatures related GAD task are only devoted to distinguishing  normal and abnormal nodes on attributed graphs, not determine one anomalous node belongs to attribute anomaly or structure anomaly. (1) we do not know one labeled anomalous data is attribute or structure anomaly. So the model cannot be trained without the labeled datasets about the anomalous types. 
Q3: What is the difference of the mask strategy between this paper and Sub-CR? It is lack of innovation.
R3: Recently, the masked strategy is prevalent in many deep learning domains. Here we are interested in the mask strategy on graphs, which includes node-level and edge-level masking manners to reduce the redundant information. We conclude the mask strategy between this paper and Sub-CR that has one similarity (1) and two differences (2)(3).
(1) both of us utilize the random walk with start (RWR) technique to sample a sequence of elements for a target and then build a sample subgraph, because RWR is an effective and economic sample method that is widely utilized in many graph models.
(2) we exploit two types of mask strategies: attribute masking and structure masking, while  Sub-CR only masks attribute to build subgraph and reconstruct.
(3) this is most critical difference. Sub-CR samples a sequence of nodes to produce a unmasked subgraph through the RWR technique, then randomly mask some nodes’ attributes to generage a masked subgraph and input it into a lightweight decoder to reconstruct the masked node’s raw attributes. For us, (i) When we sample a subgraph started from a target node, we only mask one target node’s attribute to build a masked subgraph. The reasons is that the attributes of abnormal nodes is significantly different from their neighboring nodes, we can measure the reconstruction attribute of the masked target node to distinguish whether it belongs to attribute anomaly. (ii) When we sample a subgraph started from a target edge, we obtain some edges with nodes to rebuild a subgraph, and we directly take it as a masked subgraph. We treat the process of reconstructing the edges of the masked subgraph as link prediction, which breaks the short-range connections in a dense mass to make structural anomalies must look elsewhere for evidence to fit themselves. (iii) Lastly, the details about two mask strategies is depicted in Attribute Masking and Structure Masking subsections in our manuscript. 
Thank you for carefully reviewing our paper, and sincerely hope you can have a higher evaluation for our work. 

To Reviewer #7:
We greatly thank you for the constructive comments and positive reviews. We detailedly response your questions.
Q1: Please provide the detail of the decoding step. Eq (4) is absurd since h_e[i,j] is treated as a scalar when it is a vector obtained by the element-wise multiplication. Should the element-wise multiplication be the inner product?
R1: The decoding step is aiming at reconstrucing the masked edges. To determine whether existing an edge between nodes, we measure the similarity of two nodes by the inner product to obtain a edge score. Thanks for pointing out our problem, h_e[i,j] represents a edge score, which is a scalar not a vector, so the operator should be the inner product rather than the element-wise multiplication.
Q2: Please provide the details of the clustering-based pretext. What are semantic-related nodes and how to obtain them? What is the intuition of comparing P and Q in Eq (9)?
R2: (1) First, we interpret why utilize the clustering-based pretext. The cosine distance emploied in the equation (6) can measure the similarity of two representations, but only constrains the instance-level representation similarity and cannot capture different types of anomalous patterns, while anomalous patterns usually are related to the whole data distribution. So we choose clustering-based pretext.
(2) Second, we illustrate the details of the clustering-based pretext. (i) the target network generate cluster centers and representations. (ii) compute Q and P, which connects online networks and the target network closely. (iii) compute the intra-view and the inter-view KL divergence to tie the two online networks closely in clustering space.
(3) Third, we explain the intuition of comparing P and Q in Eq (9). For unsupervised learning approaches, there are no given labels for target functions. We need an optimization that can be used to guide our online networks to facilitate the clustering-based pretext. We use Student’s t-distribution as the kernel to measure the similarity between between the latent embeddings of online networks and the clustering centers of the target network, which generates a soft cluster assignment Q. If directly optimizing Q, this will degenerate into the cosine distance, which only constrain the instance-level representation similarity rather than different distributions of anomalous patterns. To conquer this shortcoming, we introduce KL divergence to optimize. However, KL divergence need to two variable distributions, so we sharpen the soft cluster assignment Q, that not only increase the confidence of Q, but improve cluster purity. We take P as the target distribution, Q as a the soft distribution of the original distribution. KL divergence can jointly refine the embedding space of online networks and the cluster space of the target network by making the soft distribution approach the target distribution in an iterative learning way.
Q3: since a focus on this work is to reduce computational cost (by removing negative samples), the computational cost of the new tasks could be analyzed.
R3: We provide a brief description of the time and space complexities of the proposed Dual-GAD model. Consideing an undirected graph G=(V; E), where V and E represent the set of vertices and edges, respectively. Let n = |V| and m = |E| denote the number of nodes and edges in G, respectively. Each node is associated with an f-dimensional feature vector. We use A and X to represent the adjacency matrix and the feature matrix of G. Owing to the encoder, decoder, projector in our model are based on GCN module, we need to know its computational cost. For a GCN layer, the time cost and space cost can be bounded by O(mfh) and O(m) [1], where O(mf ) is the total cost of the sparse-dense matrix multiplication AX, O(fh) is the cost of the feature transformation by applying the learning matrix W, h is the output dimension of hidden layer. We can conlude that GCN is linearly related with the number of graph edges. However, we input a sampling subgraph rather than a full graph into Dual-GAD. We set the edge number of the sampling subgraph is u, then the time cost and space cost of a GCN module is O(ufh) and O(u) in our model, and u is far less than m. Dual-GAD consists of two online networks and one target, the encoder, decoder and projector are one-layer GCN. For each online network, the computational cost is O(uf^2h) + O(ufh^2), the first term is the cost of encoder-decoder (two GCN layers), the latter is the cost of encoder-projector (two GCN layers). For the target network (one GCN layer), the computational cost is O(ufh). Then the predictor is two-layer MLP, the computational cost is O(h^2). The last cost is the sampling process. The time complexity of each RWR subgraph sampling is O(Pv), where v=m/n is the mean degree of network and P is the the walk length of RWR. For the attribute masking strategy, the whole cost is O(nPv), and the whole cost is O(mPv) for the structure masking strategy. We ignore the cost for computation of the cluster and the loss fuctions in this analysis. Thus the total time and space complexity per update step for Dual-GAD is O(Pv + 2*ufh(f+h) + 2*h^2). Comparing with other baseline models, (1) our model has less memory cost because of inputing a subgraph rather than a full graph; (2) our model need less time cost in per update step. 
Reference:
[1] Kipf T N, Welling M. Semi-supervised classification with graph convolutional networks.
Q4: It seems that no supplementary material is submitted. Please let me know if that is not the case.
R4: No supplementary material.
Thank you for carefully reviewing our paper, and sincerely hope you can have a higher evaluation for our work. 

To Reviewer #8:
We greatly thank you for the constructive comments and positive reviews. We detailedly response your questions.
Q1: How can the local subgraph from RWR breaks short-range connections?
R1: RWR starts a random walk on the graph from a target node or edge. The walk iteratively travels to its multi-hop neighborhoods with the transition probability and then collect a sequence to build a induced subgraph. This subgraph includes multi-hop neighborhoods of the target rather than only one-hop neighborhoods, which we consider RWR breaks short-range connections. RWR is an effective and economic sample method that is widely utilized in many graph models. Other graph sampling algorithms such as forest fire are also available in our framework.
Q2: How can RWR avoid features being diluted by neighbors? Aren’t they still diluted by the features of their neighbors in the sampled subgraphs?
R2: (1) There are two aspects to avoid features being diluted by neighbors. First, building a subgraph from its multi-hop neighborhoods for each target node or edge, that reduces the number of surrounding nodes. Second, we introduce a attribute masking strategy. Differing from others (randomly mask multiple nodes’ attribute ), we only mask the target node. The behind intuition is that anomalies usually do not conform to expected behavior with neighbors and thus the subgraph is more rational to depict the particular properties of anomalous patterns. Moreover, this will reduce calculation complexity, because we build a subgraph for each node and mainly fouce on the induced node (target), so it is not necessary to reconstruct multiple masked nodes in one subgraph.
(2) We cannot assure that target nodes aren’t still diluted by the features of their neighbors in the sampled subgraphs. Whether the masked nodes can be correctly depicted by their neighbors, we think that this is highly related to the size of sampled subgraph, because larger subgraphs are not always required. We have carried out a parameter analysis experiment on the size of subgraphs and detailed analysis can be found in our manuscript.
Q3: Why is equation 4 a cross-entropy loss and how does this loss work to capture anomalies?
R3: Different from reconstructing masked attributes with the mean squared error (MSE) loss to detect attribute anomalies, predicting masked edges whether are malicious is a binary classification task. So the equation 4 is binary cross entropy loss function.
Q4: What does the second problem of the cosine similarity pretext task, “it fails to discover the underlying semantic structure information over the whole data distribution, which is critical to generate discriminative representations to bootstrap online networks”, mean?
R4: our paper focus on attribute and structure anomaly types, and each type has unique patterns. In the available anomalies datasets, they only tag normal and abnormal labels and we do not know one labeled anomalous data belongs to attribute or structure anomaly. This is why we devise two online networks in our Dual-GAD model. The equation 6 minimizes the cosine distance of two representations. Intuitively, if nodes of the same class share the similar patterns, pulling the same-labeled nodes together in the embedding space via the cosine similarity constraint. However, anomalous nodes  belong to the same class but have diverse patterns (i.e., attribute and structure), and two online networks will degenerate to capture the same anomalous pattern, which is not what we want. In such a case, we resort to the graph cluster method. This is because the cluster process can retain the structural and attribute properties of a graph in the form of nodes’ cluster distributions, which provide underlying semantic structure information. Moreover, leaning data distribution is easier than the instance-level learning, particularly for imbalanced datasets.
Q5: How do losses in equation (9) and (10) work to capture anomaly?
R5: (i) the equation (9) is applied to measure the the intra-view KL divergences , while the equation (9) measure the the inter-view KL divergences. To generate more reliable guidance for online networks, we has integrated the clustering information of the target network to them. 
(ii) First step is to generate a soft cluster assignment Q by measuring the similarity between the latent embeddings of online networks and the clustering centers of the target network with a Student’s t-distribution kernel. 
(iii) In the second step, to increase the confidence of Q and improve cluster purity, we employ the equation (8) to generate a target distribution P. We hope the current soft assignment Q to approach the target distribution P, such that the final optimization function can be obtained through jointly training each online networks and the target network. 
(iiii) The equation (9) is applied to measure the the intra-view KL divergences, which is devoted to capture a single type of anomaly pattern. However, owing to the target network is not be updated at each iteration, merely optimizing the equation (9) ignores the rich underlying the other anomaly pattern information, which makes the ties between two views loose in clustering space. 
(iiiii) To partially alleviate this problem, we add the equation (10) to let the soft cluster assignment of one online network to approach the the target distribution of the other online network. The cross-view clustering method not only helps to train a robust and effective target network that can output the distribution to easily distinguish normal and abnormal nodes, but also let online networks better capture different anomaly patterns. 
Q6: How is the MLP layer for computing the contrastive scores from the contrastive embeddings trained? The method is unsupervised and the contrastive scores are not used at all in the loss functions.
R6: Yes, you are right. Thank you for your professionalism and carefulness. The details of the predictor (see the framework) in the contrast module is not illustrated in our manuscript because of a hasty submission. Here we supplement the details and state the reasons.
(1)	The traditional contrast methods predict anomalous score of nodes by computing the difference between the positive pair and negative pair, while our contrast module considers to avoid bringing false negative samples owing to too few anomaly samples and choose not to depend on negative pairs. However, a posed challenge is how to look for supervised signals to train the predictor for better predictive results.
(2) To solve this challenge, we take the cluster result of the target network as the ground-truth labels, and the problem is tranlated into a binary-classification task. (i) First, we define the predictor as a MLP layer, which uses a learnable matrix W and an activation function to map nodes representation H into suspicious scores. (ii) We adopt a cross-entropy loss, the most popular one in supervised learning, to instantiate the supervised loss function with the output of the predictor and the cluster labels.
Q7: How are the recall computed, i.e., with what thresholds? Why not instead include results based on AUPR?
R7: Recall metric measures the proportion of true anomalies that a specific detection method discovered in the total number of ground truth anomalies. The threshold is set 50, i.e., Recall@50. 
ROC-AUC is widely employed to evaluate the performance of anomaly detection methods. The ROC curve represents the plot of true positive rate against false positive rate, while AUC is the area under the ROC curve. So why not use AUPR metric, we didn't really think about this. After consulting some literatures, we try to answer this question and think the main reason is that AUC is more robust than AUPR to measure the performance of imbalance dataset. AUPR needs to compute precision and recall values, but the precision is vulnerable to the data distribution. So AUPR usually is is more suitable for balanced datasets, while AUC can be applied to both balanced and imbalanced datasets.
Q8: How are anomalies injected in the datasets?
R8: Sorry, we omitted the anomalies injected scheme due to space limitations of the layout. We inject anomalies into the attributed networks by following the previous researches (i.e., DOMINANT, CoLA, Sub-CR). We inject two types of anomaly for each dataset: structural anomalies and attribute anomalies). (i) Structural anomalies injection need to generate some dense cliques. We specify the clique size as m, randomly select m nodes from the network and then make those nodes fully connected. Finally we iteratively repeat this process until a number of n cliques are generated and the total number of structral anomalies is m×n. In our experiments, we fix the clique size m=15 and set n=10, 15, 20, 20 and 5 for BlogCatalog, Flickr and ACM, Pubmed and Cora, respectively. Attribute anomalies injection is to perturb the attribute of nodes. (ii) To guarantee an equal number of two types anomalies, we first randomly select another m × n nodes. Taking each selected node as target , we sample another k nodes as a candidate set, and calculate the Euclidean distance between the target and the nodes in a candidate set. Then we pick the node which has the largest Euclidean distance to the target, and change the attribute of the target with the node. In our experiments, we set the value of k to 50.
Thank you for carefully reviewing our paper, and sincerely hope you can have a higher evaluation for our work. 

To Reviewer #9:
We greatly thank you for the constructive comments and positive reviews. We detailedly response your questions.
Q1: Missed GAN based implementations such as TAD GAN, MC GAN which should be ideally used as baselines. These approaches have lately shown promise in detecting anomalies in data outperforming all chosen standard baselines. It is difficult to quantify improvement without an explicit comparison with these state of the art approaches.
R1: Thanks for the intelligent proposal, which inspires me to advance the direction that emploies GAN to solve graph anomaly detection problem in the future, because currently there is less work about the GAN-based graph anomaly detection. First say sorry, there are many models who name MC-GAN, but I cannot search a paper related with the anomaly detection task. Anyway, I deeply believe your knowledgeable nomination. TAD-GAN and MCD-GAN are prominent to detecte anomalies, but they are tailored for the time series anomaly detection domain, while I focus on the anomalies on static graphs that lack the time-dimension information. So I cannot take my graph datasets input the two approaches to further quantify improvement of my model. However, I still thank you very much to inspire me, I will add the two approaches to the related work section in my manuscript. Moreover, my future research will  focus on graph anomaly detection associated with time series information.
Q2: Some grammatical errors and typos in the paper (for example - We choose five “real-word” graph datasets for the anomaly detection task (Experiments section)….)
R2: Thanks for your carefulness. I revise these grammatical errors and typos as below:
We choose five real-world graph datasets for the anomaly detection task, which includes two social network datasets (BlogCatalog, Flickr) and three citation network datasets (ACM, Pubmed, Cora). A detailed description of these datasets can be found in (Zheng et al. 2021). Table 1 summarizes the statistics of each dataset.
Q3: Missing Overhead analysis: What is the computational and time overhead of the proposed approach when compared with the chosen baselines.
R3: We provide a brief description of the time and space complexities of the proposed Dual-GAD model. Consideing an undirected graph G=(V; E), where V and E represent the set of vertices and edges, respectively. Let n = |V| and m = |E| denote the number of nodes and edges in G, respectively. Each node is associated with an f-dimensional feature vector. We use A and X to represent the adjacency matrix and the feature matrix of G. Owing to the encoder, decoder, projector in our model are based on GCN module, we need to know its computational cost. For a GCN layer, the time cost and space cost can be bounded by O(mfh) and O(m) [1], where O(mf ) is the total cost of the sparse-dense matrix multiplication AX, O(fh) is the cost of the feature transformation by applying the learning matrix W, h is the output dimension of hidden layer. We can conlude that GCN is linearly related with the number of graph edges. However, we input a sampling subgraph rather than a full graph into Dual-GAD. We set the edge number of the sampling subgraph is u, then the time cost and space cost of a GCN module is O(ufh) and O(u) in our model, and u is far less than m. Dual-GAD consists of two online networks and one target, the encoder, decoder and projector are one-layer GCN. For each online network, the computational cost is O(uf^2h) + O(ufh^2), the first term is the cost of encoder-decoder (two GCN layers), the latter is the cost of encoder-projector (two GCN layers). For the target network (one GCN layer), the computational cost is O(ufh). Then the predictor is two-layer MLP, the computational cost is O(h^2). The last cost is the sampling process. The time complexity of each RWR subgraph sampling is O(Pv), where v=m/n is the mean degree of network and P is the the walk length of RWR. For the attribute masking strategy, the whole cost is O(nPv), and the whole cost is O(mPv) for the structure masking strategy. We ignore the cost for computation of the cluster and the loss fuctions in this analysis. Thus the total time and space complexity per update step for Dual-GAD is O(Pv + 2*ufh(f+h) + 2*h^2). Comparing with other baseline models, (1) our model has less memory cost because of inputing a subgraph rather than a full graph; (2) our model need less time cost in per update step. 
Reference:
[1] Kipf T N, Welling M. Semi-supervised classification with graph convolutional networks.
Thank you for carefully reviewing our paper, and sincerely hope you can have a higher evaluation for our work. 


